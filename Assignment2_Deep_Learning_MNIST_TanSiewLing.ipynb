{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_Deep_Learning_MNIST_TanSiewLing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1R8IqQrNV079",
        "GYFBWi3FVXol",
        "kJKoqn50Iw_-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R8IqQrNV079"
      },
      "source": [
        "# **PART B - Deep Learning (MNIST)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYFBWi3FVXol"
      },
      "source": [
        "### Implement an image classifier using a deep learning network. [Hint: You may wish to refer to papers on successful DL architectures such as AlexNet]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsGoS1cnT2D3"
      },
      "source": [
        "Write a short report (e.g. in Notebook) detailing your implementation, your\n",
        "experiments and analysis. In particular, we'd like to know:\n",
        "\n",
        "• How is your prediction task defined? And what is the meaning of the\n",
        "output variable?\n",
        "\n",
        "• How do you represent your data as features?\n",
        "\n",
        "• Did you process the features in any way?\n",
        "\n",
        "• Did you bring in any additional sources of data?\n",
        "\n",
        "• How did you select which DL model to use?\n",
        "\n",
        "• Did you try to tune the hyperparameters of the learning algorithm, and in\n",
        "that case how?\n",
        "\n",
        "• How do you evaluate the quality of your system?\n",
        "\n",
        "• Can you say anything about the errors that the system makes? \n",
        "For a classification task, you may consider a confusion matrix.\n",
        "\n",
        "• Is it possible to say something about which features the model considers\n",
        "important? (Whether this is possible depends on the type of classifier\n",
        "you are using)\n",
        "• Provide a reference section for any papers, online articles, books,\n",
        "publications that you have referenced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJKoqn50Iw_-"
      },
      "source": [
        "# Prediction task definition :\n",
        "\n",
        "To classify/recognise handwritten digit images\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8154WLOZRAWS"
      },
      "source": [
        "# Output variable : the digits (0-9)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6exfnjVcaHO"
      },
      "source": [
        "\n",
        "• How do you represent your data as features?\n",
        "\n",
        "• Did you process the features in any way?\n",
        "\n",
        "• Did you bring in any additional sources of data?\n",
        "\n",
        "• How did you select which DL model to use?\n",
        "\n",
        "• Did you try to tune the hyperparameters of the learning algorithm, and in\n",
        "that case how?\n",
        "\n",
        "• How do you evaluate the quality of your system?\n",
        "\n",
        "• Can you say anything about the errors that the system makes? \n",
        "For a classification task, you may consider a confusion matrix.\n",
        "\n",
        "• Is it possible to say something about which features the model considers\n",
        "important? (Whether this is possible depends on the type of classifier\n",
        "you are using)\n",
        "• Provide a reference section for any papers, online articles, books,\n",
        "publications that you have referenced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM6SKs9AWCYk"
      },
      "source": [
        "# LOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDXLY47ZALLw"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XogrFNXtAQZs",
        "outputId": "abd85dbc-52e5-4181-cd2c-07da5cd7756a"
      },
      "source": [
        "#load the mnist dataset\n",
        "\n",
        "#already split, no need split into train and test. unless u want to split a validation set from train set\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIcXHWqaAxVN"
      },
      "source": [
        "#validation set\n",
        "#X_validation, y_validation = X_train[:5000], y_train[:5000]\n",
        "#X_train, y_train = X_train[5000:], y_train[5000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbWgv_JD03Nt"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "PQcF4Ey_33EI",
        "outputId": "b00dcfee-8bb4-4ad3-bd00-b00ed9312262"
      },
      "source": [
        "# plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "#plt.subplot(231)\n",
        "#plt.imshow(X_train[4], cmap=plt.get_cmap('gray'))\n",
        "#plt.subplot(232)\n",
        "#plt.imshow(X_train[5], cmap=plt.get_cmap('gray'))\n",
        "#plt.subplot(233)\n",
        "#plt.imshow(X_train[6], cmap=plt.get_cmap('gray'))\n",
        "#plt.subplot(234)\n",
        "#plt.imshow(X_train[7], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5MDuEfg5DYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80087f92-8905-4f23-d929-398996669c7d"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "print(X_train[0])\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_train[:20])\n",
        "\n",
        "print(y_test.shape)\n",
        "print(y_test[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  97  96  77 118  61   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0  90 138 235 235 235 235 235 235 251 251 248 254 245 235 190\n",
            "   21   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0 140 251 254 254 254 254 254 254 254 254 254 254 254 254 254 254\n",
            "  189  23   0   0   0   0   0   0   0   0]\n",
            " [  0   0 226 254 208 199 199 199 199 139  61  61  61  61  61 128 222 254\n",
            "  254 189  21   0   0   0   0   0   0   0]\n",
            " [  0   0  38  82  13   0   0   0   0   0   0   0   0   0   0   0  34 213\n",
            "  254 254 115   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  84\n",
            "  254 254 234   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  84\n",
            "  254 254 234   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 106 157\n",
            "  254 254 243  51   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  25 117 228 228 228 253 254\n",
            "  254 254 254 240   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  68 119 220 254 254 254 254 254 254\n",
            "  254 254 254 142   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  37 187 253 254 254 254 223 206 206  75  68\n",
            "  215 254 254 117   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 113 219 254 242 227 115  89  31   0   0   0   0\n",
            "  200 254 241  41   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 169 254 176  62   0   0   0   0   0   0   0  48\n",
            "  231 254 234   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 124   0   0   0   0   0   0   0   0   0  84\n",
            "  254 254 166   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 139\n",
            "  254 238  57   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 210 250\n",
            "  254 168   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 242 254\n",
            "  239  57   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  89 251 241\n",
            "   86   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5 206 246 157\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   4 117  69   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "(55000,)\n",
            "[7 3 4 6 1 8 1 0 9 8 0 3 1 2 7 0 2 9 6 0]\n",
            "(10000,)\n",
            "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODCRu3f3uFNw"
      },
      "source": [
        "3-dimensional array of instance,image width and image height. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNP-kOL88led"
      },
      "source": [
        "explore data using histogram?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDlGaRbxAqT7"
      },
      "source": [
        "# Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFn1wxV0BfA2"
      },
      "source": [
        "# **(a) Scaling**\n",
        "- to normalize inputs from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE5Uv9drBfXO"
      },
      "source": [
        "#X - do scaling\n",
        "# normalize inputs from 0-255 to 0-1 , no need call standard scalar\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAC4pC9T62nk"
      },
      "source": [
        "# **(b) One-Hot encoding**\n",
        "\n",
        "so that 1 integer can represent 10 output neurons using softmax activation\n",
        "convert 1 single column to 10 columns\n",
        "-separate neuron for each output class\n",
        "\n",
        "We need convert the digit integer into a representation that can fit 10 output neurons. And use softmax activation. One-hot encode the values. I0-I1-I2-I3-I4-I5-I6-I7-I8-I9\n",
        "0-0-0-0-1-0-0-0-0-0\n",
        "\n",
        "4=0-0-0-0-1-0-0-0-0-0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C6Q5iXWBM1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6098e1d9-298a-4d64-f0d0-bb07e216f4ab"
      },
      "source": [
        "\n",
        "# Y - one hot encode outputs so as to represent 10 outputs\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19mXlj4TBbpU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIQNVBMOB6aC"
      },
      "source": [
        "# Model used - Complex CNN\n",
        "\n",
        "- less trainable weight (due to max pooling)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-g4aUphx4R7"
      },
      "source": [
        "model consist of :\n",
        "\n",
        "(a) Input Layer :\n",
        "\n",
        "Convolutional Layer: Conv2D - filter size (3,3), 30 filters\n",
        "\n",
        "Pooling Layer : MaxPooling2D - pool size (2,2) to downsize the image and hence reduce the trainable parameters\n",
        "\n",
        "Best Practices - All layers use the ReLU activation function and the he_uniform kernel initializer ( weight initialization scheme)\n",
        "\n",
        "(B) Hidden Layers:\n",
        "\n",
        "Convolutional Layer: Conv2D - filter size (3,3), 15 filters\n",
        "Pooling Layer : MaxPooling2D - pool size (2,2) \n",
        "\n",
        "Dropout Layer : For  regularization - randomly reducing the number of interconnecting neurons within a neural network based on the given probability (0.5) to avoid overfitting.\n",
        "\n",
        "Flatten Layer :  flattens input image data into a one-dimensional array.\n",
        "\n",
        "Dense Layer: to interpret the features with 100 nodes\n",
        "\n",
        "Dense Layer: to interpret the features with 50 nodes\n",
        "\n",
        "\n",
        "(C) Output Layer:\n",
        "\n",
        "Dense Layer : - With 10 neurons/nodes to predict the image belonging to one of the 10 digits (0-9) using softmax activation function\n",
        "\n",
        "\n",
        "Compile the model with  categorical cross-entropy loss function optimized with adam optimizer and the classification accuracy metric\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t984UuoUoFsP"
      },
      "source": [
        "# Hyperparameters tuning:\n",
        "\n",
        "\n",
        "**Number of epochs**\n",
        "\n",
        "- tune from 10 to 20 until the gap between the test error and the training error is small\n",
        "\n",
        "- As the epoch increased from 10 to 99, the error gradually drop to below 6 but this increases the training time as the training set will have to pass the network 99 times!\n",
        "\n",
        "**Batch size**\n",
        "\n",
        "- tested from 16 to 100 to 150 to 200\n",
        "- as batch size increases, the error gradually decrease\n",
        "\n",
        "\n",
        "**Number of hidden layers and units**\n",
        "\n",
        "- Added 1 pair of Convolution layer and Pooling layer besides the input layer pair\n",
        "- Added 2 dense layers\n",
        "\n",
        "until test error no longer improves. \n",
        "\n",
        "**Dropout for regularization**\n",
        "\n",
        "- tune from 0.2 to 0.5 to increase the probability of dropping out the nodes in the neural network to regularize to avoid overfitting\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKXxGMf5CAh7",
        "outputId": "66b7ea09-6fae-4418-e4a4-c8af85cd7cec"
      },
      "source": [
        "# Complex CNN Model\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 88\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Data Pre-processing\n",
        "\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "print(num_pixels)\n",
        "\n",
        "# flatten 28*28 pixel images to a 784 pixels vector (single array) for each image\n",
        "#convert from integer to float (0 (black) -255(white) )\n",
        "#convert float because matix multiplcation in neural network works better with float\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "#X - do scaling\n",
        "# normalize inputs from 0-255 to 0-1 , no need call standard scalar\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# Y - one hot encode outputs so as to represent 10 outputs\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "print(num_classes)\n",
        "\n",
        "# build the model\n",
        "# create model\n",
        "model = Sequential()\n",
        "\n",
        "#input layer\n",
        "\n",
        "#Conv layer (filter layer) need input shape,28x28x1(NHWC) - 1 colour (monochrome)\n",
        "#filter size (5,5), number of filters=32\n",
        "#model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu', kernel_initializer='he_uniform'))#0.60%\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #pooling layer is a compression layer - downsize image (insert in between conv layer but don't too much, the original image will be gone)\n",
        "\n",
        "# Hidden layers\n",
        "#model.add(Conv2D(15, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(15, (3, 3), activation='relu', kernel_initializer='he_uniform'))#0.76\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5)) #tune from 0.2 to 0.5\n",
        "model.add(Flatten())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(50, activation='relu', kernel_initializer='he_uniform'))\n",
        "\n",
        "#output layer - 10 neurons to predict the images of 10 digits (0-9)\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "#opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "#model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# Fit the model\n",
        "historyCOM = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=200, verbose=2)#0.60\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "784\n",
            "10\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 30)        780       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 12, 12, 30)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 10, 10, 15)        4065      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 5, 5, 15)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 5, 5, 15)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 375)               0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 375)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 100)               37600     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 48,005\n",
            "Trainable params: 48,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "300/300 - 2s - loss: 0.5294 - accuracy: 0.8263 - val_loss: 0.0860 - val_accuracy: 0.9718\n",
            "Epoch 2/20\n",
            "300/300 - 1s - loss: 0.1460 - accuracy: 0.9543 - val_loss: 0.0536 - val_accuracy: 0.9826\n",
            "Epoch 3/20\n",
            "300/300 - 1s - loss: 0.1122 - accuracy: 0.9642 - val_loss: 0.0428 - val_accuracy: 0.9856\n",
            "Epoch 4/20\n",
            "300/300 - 1s - loss: 0.0941 - accuracy: 0.9705 - val_loss: 0.0365 - val_accuracy: 0.9874\n",
            "Epoch 5/20\n",
            "300/300 - 1s - loss: 0.0834 - accuracy: 0.9734 - val_loss: 0.0333 - val_accuracy: 0.9877\n",
            "Epoch 6/20\n",
            "300/300 - 1s - loss: 0.0777 - accuracy: 0.9762 - val_loss: 0.0318 - val_accuracy: 0.9887\n",
            "Epoch 7/20\n",
            "300/300 - 1s - loss: 0.0695 - accuracy: 0.9780 - val_loss: 0.0298 - val_accuracy: 0.9902\n",
            "Epoch 8/20\n",
            "300/300 - 1s - loss: 0.0663 - accuracy: 0.9792 - val_loss: 0.0253 - val_accuracy: 0.9914\n",
            "Epoch 9/20\n",
            "300/300 - 1s - loss: 0.0624 - accuracy: 0.9806 - val_loss: 0.0275 - val_accuracy: 0.9903\n",
            "Epoch 10/20\n",
            "300/300 - 1s - loss: 0.0553 - accuracy: 0.9821 - val_loss: 0.0234 - val_accuracy: 0.9914\n",
            "Epoch 11/20\n",
            "300/300 - 1s - loss: 0.0557 - accuracy: 0.9821 - val_loss: 0.0225 - val_accuracy: 0.9919\n",
            "Epoch 12/20\n",
            "300/300 - 1s - loss: 0.0544 - accuracy: 0.9825 - val_loss: 0.0247 - val_accuracy: 0.9916\n",
            "Epoch 13/20\n",
            "300/300 - 1s - loss: 0.0504 - accuracy: 0.9837 - val_loss: 0.0260 - val_accuracy: 0.9911\n",
            "Epoch 14/20\n",
            "300/300 - 1s - loss: 0.0502 - accuracy: 0.9838 - val_loss: 0.0214 - val_accuracy: 0.9927\n",
            "Epoch 15/20\n",
            "300/300 - 1s - loss: 0.0460 - accuracy: 0.9849 - val_loss: 0.0227 - val_accuracy: 0.9916\n",
            "Epoch 16/20\n",
            "300/300 - 1s - loss: 0.0443 - accuracy: 0.9861 - val_loss: 0.0258 - val_accuracy: 0.9917\n",
            "Epoch 17/20\n",
            "300/300 - 1s - loss: 0.0405 - accuracy: 0.9868 - val_loss: 0.0191 - val_accuracy: 0.9936\n",
            "Epoch 18/20\n",
            "300/300 - 1s - loss: 0.0408 - accuracy: 0.9865 - val_loss: 0.0210 - val_accuracy: 0.9926\n",
            "Epoch 19/20\n",
            "300/300 - 1s - loss: 0.0394 - accuracy: 0.9869 - val_loss: 0.0218 - val_accuracy: 0.9924\n",
            "Epoch 20/20\n",
            "300/300 - 1s - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0207 - val_accuracy: 0.9935\n",
            "CNN Error: 0.65%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fOwxGSXB8ct"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "g8NzFXx_FpzL",
        "outputId": "d69d2734-060b-4182-b2b8-e7e0eb0aabe2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot history: MAE\n",
        "plt.plot(historyCOM.history['loss'], label='MAE (training data)')\n",
        "plt.ylim(-0.05, 0.5)\n",
        "plt.plot(historyCOM.history['val_loss'], label='MAE (validation data)')\n",
        "\n",
        "plt.title('Loss')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.ylim(-0.05, 0.5)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcR7fUCF6eSa"
      },
      "source": [
        "Evaluation - Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "kyXmqAto-Q6I",
        "outputId": "912eaad8-df30-499c-c7e6-7d4d540bb12e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "# Confusion matrix\n",
        "#confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#precision_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.63197658e-15 1.31283984e-10 1.00637326e-12 ... 1.00000000e+00\n",
            "  5.21985536e-15 9.23041366e-11]\n",
            " [3.40640127e-10 5.79427760e-05 9.99942064e-01 ... 5.17854426e-09\n",
            "  2.03801906e-11 2.72724090e-13]\n",
            " [1.07323046e-10 9.99999523e-01 4.40671555e-10 ... 4.84548792e-08\n",
            "  7.01780678e-09 2.94204688e-10]\n",
            " ...\n",
            " [1.37237859e-19 1.25608562e-12 9.45279769e-16 ... 2.64428263e-13\n",
            "  1.71683284e-12 2.20733046e-12]\n",
            " [6.17268061e-15 1.06518450e-16 4.84890225e-19 ... 8.31369508e-16\n",
            "  4.29523301e-12 1.51942532e-13]\n",
            " [1.38262957e-08 2.97206926e-10 8.36078595e-10 ... 3.22368339e-14\n",
            "  6.67108537e-08 7.31404780e-12]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-d7c2897ea0c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#confusion_matrix(y_test, y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1670\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1673\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                          str(average_options))\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWBTY6f2NIqS"
      },
      "source": [
        "References:\n",
        "\n",
        "https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/\n",
        "\n",
        "\n",
        "https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2021/06/mnist-dataset-prediction-using-keras/\n",
        "\n",
        "https://www.kaggle.com/prashant111/mnist-deep-neural-network-with-keras\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python\n",
        "\n",
        "https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00444-8\n",
        "\n",
        "https://towardsdatascience.com/implementing-alexnet-cnn-architecture-using-tensorflow-2-0-and-keras-2113e090ad98\n",
        "\n",
        "https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/\n",
        "\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/cnn-tensorflow-python\n",
        "\n",
        "https://towardsdatascience.com/a-walkthrough-of-convolutional-neural-network-7f474f91d7bd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg_BNET1VVvE"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhLRbVV4vlpq",
        "outputId": "03c9bdef-6aa9-4bbd-d872-ea97659fe432"
      },
      "source": [
        "# Complex CNN Model\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 88\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Data Pre-processing\n",
        "\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "print(num_pixels)\n",
        "\n",
        "# flatten 28*28 pixel images to a 784 pixels vector (single array) for each image\n",
        "#convert from integer to float (0 (black) -255(white) )\n",
        "#convert float because matix multiplcation in neural network works better with float\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "#X - do scaling\n",
        "# normalize inputs from 0-255 to 0-1 , no need call standard scalar\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# Y - one hot encode outputs so as to represent 10 outputs\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "print(num_classes)\n",
        "\n",
        "# build the model\n",
        "# create model\n",
        "model = Sequential()\n",
        "\n",
        "#input layer\n",
        "\n",
        "#Conv layer (filter layer) need input shape,28x28x1(NHWC) - 1 colour (monochrome)\n",
        "#filter size (5,5), number of filters=32\n",
        "model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu', kernel_initializer='he_uniform'))#0.60%\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #pooling layer is a compression layer - downsize image (insert in between conv layer but don't too much, the original image will be gone)\n",
        "\n",
        "# Hidden layers\n",
        "model.add(Conv2D(15, (3, 3), activation='relu', kernel_initializer='he_uniform'))#0.76\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5)) #tune from 0.2 to 0.5\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(50, activation='relu', kernel_initializer='he_uniform'))\n",
        "\n",
        "#output layer - 10 neurons to predict the images of 10 digits (0-9)\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# Fit the model\n",
        "historyCOM = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=200, verbose=2)#0.60\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "784\n",
            "10\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 24, 24, 30)        780       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 12, 12, 30)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 10, 10, 15)        4065      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 5, 5, 15)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 5, 5, 15)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 375)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 100)               37600     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 48,005\n",
            "Trainable params: 48,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "300/300 - 2s - loss: 0.8836 - accuracy: 0.6990 - val_loss: 0.1405 - val_accuracy: 0.9567\n",
            "Epoch 2/20\n",
            "300/300 - 1s - loss: 0.2596 - accuracy: 0.9179 - val_loss: 0.0877 - val_accuracy: 0.9728\n",
            "Epoch 3/20\n",
            "300/300 - 1s - loss: 0.1994 - accuracy: 0.9375 - val_loss: 0.0708 - val_accuracy: 0.9763\n",
            "Epoch 4/20\n",
            "300/300 - 1s - loss: 0.1745 - accuracy: 0.9448 - val_loss: 0.0651 - val_accuracy: 0.9788\n",
            "Epoch 5/20\n",
            "300/300 - 1s - loss: 0.1600 - accuracy: 0.9496 - val_loss: 0.0572 - val_accuracy: 0.9812\n",
            "Epoch 6/20\n",
            "300/300 - 1s - loss: 0.1437 - accuracy: 0.9540 - val_loss: 0.0516 - val_accuracy: 0.9832\n",
            "Epoch 7/20\n",
            "300/300 - 1s - loss: 0.1366 - accuracy: 0.9578 - val_loss: 0.0494 - val_accuracy: 0.9844\n",
            "Epoch 8/20\n",
            "300/300 - 1s - loss: 0.1279 - accuracy: 0.9592 - val_loss: 0.0445 - val_accuracy: 0.9863\n",
            "Epoch 9/20\n",
            "300/300 - 1s - loss: 0.1172 - accuracy: 0.9635 - val_loss: 0.0384 - val_accuracy: 0.9868\n",
            "Epoch 10/20\n",
            "300/300 - 1s - loss: 0.1125 - accuracy: 0.9649 - val_loss: 0.0388 - val_accuracy: 0.9873\n",
            "Epoch 11/20\n",
            "300/300 - 1s - loss: 0.1094 - accuracy: 0.9658 - val_loss: 0.0356 - val_accuracy: 0.9883\n",
            "Epoch 12/20\n",
            "300/300 - 1s - loss: 0.1023 - accuracy: 0.9679 - val_loss: 0.0363 - val_accuracy: 0.9874\n",
            "Epoch 13/20\n",
            "300/300 - 1s - loss: 0.1034 - accuracy: 0.9677 - val_loss: 0.0367 - val_accuracy: 0.9877\n",
            "Epoch 14/20\n",
            "300/300 - 1s - loss: 0.0986 - accuracy: 0.9681 - val_loss: 0.0358 - val_accuracy: 0.9884\n",
            "Epoch 15/20\n",
            "300/300 - 1s - loss: 0.0952 - accuracy: 0.9699 - val_loss: 0.0313 - val_accuracy: 0.9900\n",
            "Epoch 16/20\n",
            "300/300 - 1s - loss: 0.0935 - accuracy: 0.9700 - val_loss: 0.0310 - val_accuracy: 0.9892\n",
            "Epoch 17/20\n",
            "300/300 - 1s - loss: 0.0911 - accuracy: 0.9710 - val_loss: 0.0293 - val_accuracy: 0.9901\n",
            "Epoch 18/20\n",
            "300/300 - 1s - loss: 0.0901 - accuracy: 0.9707 - val_loss: 0.0302 - val_accuracy: 0.9897\n",
            "Epoch 19/20\n",
            "300/300 - 1s - loss: 0.0869 - accuracy: 0.9729 - val_loss: 0.0288 - val_accuracy: 0.9906\n",
            "Epoch 20/20\n",
            "300/300 - 1s - loss: 0.0863 - accuracy: 0.9723 - val_loss: 0.0303 - val_accuracy: 0.9902\n",
            "CNN Error: 0.98%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}